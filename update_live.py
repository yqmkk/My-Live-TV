import requests
import re
import concurrent.futures
import time

# --- æ ¸å¿ƒé…ç½® ---
SEARCH_KEYWORDS = {
    "ğŸ‡¨ğŸ‡³ä¸­å›½é«˜æ¸…": ["CCTV", "å«è§†", "æ•°å­—", "ç”µå½±", "å‰§åœº", "æ–°é—»", "ä½“è‚²", "4K", "8K"],
    "ğŸ‡ºğŸ‡¸ç¾å›½ç²¾é€‰": ["CNN", "HBO", "FOX", "ABC", "NBC", "USA", "DISCOVERY", "MOVIES"],
    "ğŸ‡¯ğŸ‡µæ—¥æœ¬ç²¾é€‰": ["NHK", "BS", "NTV", "TOKYO", "FUJI", "ASAHI"],
    "ğŸ‡°ğŸ‡·éŸ©å›½ç²¾é€‰": ["KBS", "MBC", "SBS", "TVN", "MNET"]
}

RAW_SOURCES = [
    "https://raw.githubusercontent.com/hujingguang/ChinaIPTV/main/cnTV_AutoUpdate.m3u8",
    "https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/ipv6.m3u",
    "https://raw.githubusercontent.com/Guovern/tv-list/main/m3u/chinatv.m3u",
    "https://raw.githubusercontent.com/billy21/Tvlist-awesome-m3u-m3u8/master/m3u/migu.m3u",
    "https://iptv-org.github.io/iptv/index.m3u",
    "https://raw.githubusercontent.com/YueChan/Live/main/IPTV.m3u"
]

EPG_SOURCE = "http://epg.51zmt.top:8000/e.xml"
TIMEOUT = 4
MAX_WORKERS = 60

def clean_name(name):
    """æå…¶ä¸¥æ ¼çš„åå­—æ¸…æ´—ï¼Œç”¨äºå½»åº•å»é‡"""
    name = name.upper()
    # ç§»é™¤æ‰€æœ‰æ‚è´¨
    name = re.sub(r'\[.*?\]|ï¼ˆ.*?ï¼‰|\(.*?\)|é«˜æ¸…|æ ‡æ¸…|HD|SD|é¢‘é“|å­—å¹•|IPV6|IPV4|PLUS|\+', '', name)
    name = name.replace('-', '').replace(' ', '').replace('ç»¼åˆ', '')
    
    # CCTV ç‰¹æ®Šå¤„ç†
    if "CCTV" in name:
        match = re.search(r'CCTV(\d+)', name)
        if match: return f"CCTV-{match.group(1)}"
        if "æ–°é—»" in name: return "CCTV-13"
        if "å°‘å„¿" in name: return "CCTV-14"
        if "éŸ³ä¹" in name: return "CCTV-15"
    return name.strip()

def check_channel(channel):
    name, url = channel
    std_name = clean_name(name)
    
    # åŒ¹é…åˆ†ç±»
    target_group = next((g for g, keys in SEARCH_KEYWORDS.items() if any(k in std_name or k in name.upper() for k in keys)), None)
    if not target_group: return None

    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) TiviMate/4.7.0'}
        start = time.time()
        # ä»…è¯·æ±‚ Header
        r = requests.get(url, timeout=TIMEOUT, stream=True, headers=headers)
        if r.status_code == 200:
            delay = time.time() - start
            return {"name": std_name, "url": url, "group": target_group, "delay": delay}
    except:
        pass
    return None

def main():
    print("ğŸš€ å¼€å§‹æ·±åº¦å»é‡æŠ“å–...")
    all_raw_tasks = []
    seen_urls = set()

    for s in RAW_SOURCES:
        try:
            r = requests.get(s, timeout=10)
            name = ""
            for line in r.text.split('\n'):
                line = line.strip()
                if line.startswith("#EXTINF"):
                    m = re.search(r',(.+)$', line)
                    name = m.group(1) if m else ""
                elif line.startswith("http") and name:
                    if line not in seen_urls:
                        all_raw_tasks.append((name, line))
                        seen_urls.add(line)
        except: continue

    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = [executor.submit(check_channel, t) for t in all_raw_tasks]
        for f in concurrent.futures.as_completed(futures):
            res = f.result()
            if res: results.append(res)

    # --- æ ¸å¿ƒå»é‡é€»è¾‘ ---
    # å…ˆæŒ‰å»¶è¿Ÿä»å°åˆ°å¤§æ’åº
    results.sort(key=lambda x: x['delay'])
    
    unique_channels = {} # { "CCTV-1": [item1, item2], "HBO": [item1] }
    for item in results:
        name = item['name']
        if name not in unique_channels:
            unique_channels[name] = []
        # æ¯ä¸ªé¢‘é“åä¸‹åªä¿ç•™å‰ 2 æ¡æœ€å¿«çš„çº¿
        if len(unique_channels[name]) < 2:
            unique_channels[name].append(item)

    # å±•å¼€å†™å› M3U
    final_output = []
    for name in unique_channels:
        final_output.extend(unique_channels[name])
    
    # æœ€ç»ˆæŒ‰åˆ†ç±»æ’åº
    final_output.sort(key=lambda x: (x['group'], x['name']))

    with open("live_all.m3u", "w", encoding="utf-8") as f:
        f.write(f'#EXTM3U x-tvg-url="https://raw.githubusercontent.com/yqmkk/My-Live-TV/main/epg.xml"\n')
        for item in final_output:
            logo = f"https://live.fanmingming.com/tv/{item['name']}.png"
            f.write(f'#EXTINF:-1 tvg-name="{item["name"]}" tvg-logo="{logo}" group-title="{item["group"]}",{item["name"]}\n')
            f.write(f'{item["url"]}\n')

    # åŒæ­¥ EPG
    try:
        epg = requests.get(EPG_SOURCE, timeout=60).content
        with open("epg.xml", "wb") as f: f.write(epg)
    except: pass
    print(f"ğŸ‰ å»é‡å®Œæˆï¼å…±ä¿ç•™ {len(final_output)} ä¸ªæé€Ÿé¢‘é“ã€‚")

if __name__ == "__main__":
    main()
